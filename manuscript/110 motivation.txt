# Motivation

Single-window apps work well with a single process. Until you want to delegate time-consuming tasks to background processes to make the user-facing applicaton more light-weight, that is. Then you have to worry about helper processes.

Apps which live as menu bar items can become problematic, too. Conventional status-bar only apps don't fare too well with the Dock. If you want to launch real windows, they tend to get lost in the window hierarchy. Apps which present both a status-bar item and a Dock icon stay in the way all the time. They don't do well as always-on services. So you split the app into two executables and thus two independent processes.

If you have two pieces of an app working independently, you will have to figure out how to coordinate them and how to share data. Maybe both can access the same database. Maybe they need a server -- or a third, hub-like component.

In this book, we will explore a rather complex setup so you're prepared for the worst.

Let us get down to the dirt. Let me share my story so both you and I know what kind of real-world problems we're going to solve.


## My Story: the Word Counter for Mac


I develop the [Word Counter for Mac](http://wordcounterapp.com). It's a system-wide progress and productivity monitor for writers.

From the Decomber 2014 point of view, to make it grow and become more and more useful, the app has to deal with more incoming data. It also needs to analyze data and display meaningful information to the user. So both the background work and user interface become increasingly complex to develop.

When I added daily bar charts based on the excellent CorePlot in 2014, I seemed to have introduced a bug. I didn't know if it was my fault or something hidden deeply within CorePlot. But it was related to the chart, that much I could tell. Weirdly enough, the crashes didn't occur when you interact with the charts, but at some seemingly random future point in time, so the user won't notice.

It's okay when you find out your app crashes. This happens. We developers simply have to fix the bug and move on.

It dawned on me, though, that me taking the easy route earlier in the process was part of the problem of pinning down the source of the crash. I have started the app as a single executable, single-process application.

Putting the counting of words, their analysis, and the user interface into a single executable causes trouble. To put both the background service and the UI into one app means that a crash caused by the UI will also stop the counting immediately. If the app crashes silently, as it did, people will lose precious data until they notice and restart the application, if they do so at all.

Splitting the app into components promised help.

* If I put the counting on a background process, it won't stop counting when the UI crashes.
* If I put the UI for the status item and it's pop-up "Digest" view into its own Dock-less helper app, I can introduce analysis tools in a main application with a proper Dock icon.
* If I get a main app with Dock icon, the windows wouldn't need to always stay on top. Status-bar only apps don't have a Dock icon and their windows usually stay behind all other applications' windows. In other words, this will enhance user experience because the main app window behaves as expected.

The Word Counter started as a tiny app, presenting itself as a status bar item only. Then I added features which showed me that the overall design can't cope with the requirements anymore. It became too clumsy to grow further.

![201501221017 Panel Status](images/201501221017_panel-status.png)
<!--ct: TODO flow right-->

Also, introducing new features made testing harder because everything was just so involved. I put fake data at the lowest level imaginable to test-drive new UI features: I created a test target-specific directory in `~/Library/Application Support/` with dummy data just like the real app uses. What a mess!

Splitting the application into more manageable parts helps to deal with simple applications which become internally complex.

That's what this book is about: putting everything I've learned over the years together to develop a wireframe of a multi-process application.

The actual implementation of two or more processes is pretty easy. But that's only part of the solution. How do you share data? How do the parts communicate with one another? Which classes should you  share between processes?

I will cover software architecture, process implementation, and data sharing all in this book to provide an easy model to understand the problem space.


## Separating Concerns {#subsec_separateconcerns}

Developing a working application is hard enough. Why on earth would you want to fragmentize it and split up the work into multiple parts?

It's very likely that you've dabbled with concurrency already. You perform tasks on a background thread (or queue) because it can make your application more responsive. Your user interface depends on the main thread. If you block it, you can't update the UI. Users won't like that. The [spinning beach ball of death][spod] is feared everywhere and can be avoided in a lot of cases. At least for me this was the premier reason to add concurrenly to my non-trivial apps.

Wheras threads still operate on a single process, to split an application into multiple processes leads to all new concerns. How do you share data? How do you send commands? We will look into these things shortly.
<!--ct: TODO have you fulfilled the promise?-->

An application composed of multiple processes has one clear advantage: every process may fail independently. That's one reason why the Chrome browser became popular: every tab has its own process, and if it crashes because of misbehaving Flash plug-ins, for example, the rest of your browser session remains safe.[^chromeproc] If your helper process crashes, you can spawn a new one from within the main application.

I argue that even non-fatal problems can be handled easier. Since your processes don't share memory, there's no obvious shortcut to get data form A to B and vice-versa. You need to define a good API to make processes cooperate.

Say you lose the internet connection during a complex background fetch. The task can't be completed, so you abort and report the problem. The process didn't crash, but it did fail. You need to notify the main application (the _client_ of the helper) about the failure. There's a well-defined point of entry for this information.

If you use background threads, you're encouraged to keep your code clean and provide sensible callbacks, too. But there's always the possibility to let the background thread reach out into other objects. For a multi-threaded application, everythings available. The context is way bigger. Multiple processes don't share anything and thus have less context. They are dumb, more like input--output black boxes.

There's clean boundaries separating the processes from one another. This encourages a different application design altogether.

Because I think it is a fairly complex application bundle I have in mind for the Word Counter, I'll stick to the separation for the sake of this book. I make it as hard as possible so both you and I learn the most from it.

The multi-part application will be composed of:

1. a background process,
2. the "big" user interface, that is, the main application with Dock icon and all, in which users can change settings and whatnot, and
3. the helper menu bar app, where a short overview is provided.


[spod]: http://en.wikipedia.org/wiki/Spinning_pinwheel

[^chromeproc]: Remember Firefox, Flash, and how your browser crashed once or twice a day because something went wrong behind the scenes? For more details, have a look at ["Why does Chrome have so many open processes?"](http://www.howtogeek.com/124218/why-does-chrome-have-so-many-open-processes/) at HowToGeek.com. I didn't know there was a Chrome comic, but it does look fun.

## Shared Data VS Inter-Process Communication

When you splitting an application into a main app and helper service, you wall off one from the other. To make them work together, you'll have to re-introduce means of communication.

The separation this multi-process approach introduces is very strict. Compare this to adhering to principles like the Single Responsibility Principle: when you adhere to SRP, you have the choice to mix responsibilities in one place because you think it'll be too much effort not to. In your conventional single-process app, you can always break with convention. With a multi-process app, there just is no way to de-separate the processes. (Except maybe by sharing memory space.)

In a monolithic application, only the design of your objects introduces boundaries between components. You limit access intentionally, introducing modules and providing facades, to keep the code readable. Doing it this way also helps to change it later.

Good software architecture promotes change because it's easier to plug-in something different at one place. Software is changing all the time, so this is a huge win.

Coming from a monolithic app approach, one of the first questions will be this: how will all three processes share state?

They don't. Each one operates on its own. They are individual programs. The parts have access to the same files if you want them to. Or they can send notifications to communicate with one another. Just like every other program does. The difference is that _you_ design them in a way to make them work together.


### Is sharing data a good idea?

Let's say both processes access a shared directory to obtain data. Now they can share state: one process performs a change, the other reads in the new data.

Keep in mind that sharing static snapshots of data may lead to data anomalies because multiple clients perform operations concurrently. Instead of looking at snapshots of data, you may want to create ways to inform relevant processes about changes. Then again, maybe it's not going to be bad after all if the database management system (DBMS) takes care of concurrenct access. You have to weigh the benefits and drawbacks here.

We should make sure that changes take effect eventually. There is no way to guarantee instant updates. Better get comfortable with delays, no matter how short, and design your program to deal with it.

Programmers often want to develop programs which react immediately, even if a network connection and complex data crunching is involved. Instead, opt-in to eventual consistency and think about how much of a delay is okay for your users.

Eventual consistency basically states that all processes involved will eventually but not immediately return the most up-to-date value if no changes are performed anymore. If you change something, one process will be ahead of the others for some time. By how much they lag behind depends on your requirements.

The Word Counter for example can make use of a live counter in the menu bar. Some users will love to see the counter increase while they type. But do they have to have immediate feedback? If so, I'd need to add a way to instantly notify the status item about the change. That'd be nice, but does the experience suffer if UI updates take place every two seconds only? Maybe the counter will increase by 3 or 5, depending on the typing speed of the user. What about every half second? This will be more accurate, but it'll increase the amount of updates by a factor of 4!

To weigh the costs and payoff can relax the requirements a lot. I guess users will like to watch the counter increase immediately at first, but then they'll be busy writing and not pay attention. Thus, the update interval can start at once per second and increase to every two or three seconds when the user begins to write more. The UI can adapt to the user to save CPU cycles.

Relaxing the rules a bit in favor of subtle delays can change the entire approach you'll take. Immediacy goes hand in hand with strong coupling and synchronicity. Being okay with eventual consistency makes asynchronous notifications favorable.

So there's really two things we will have to take care of:

1. How do the processes share _state_? In the case of the Word Counter, this may be the daily total word count.
2. How do the processes _communicate_ with one another? The background task may want to inform the others about changes.

Do we need to share a data store or can we fetch all information from the background process just like you query a HTTP server for data?

<!--ct: TODO streamline this section: add introduction, clear aim-->

I encourage a server--client relationship in this case, with the background process acting as server because it's always on, and the user interfaces acting as clients.

## Inter-Process Communication on the Mac

There are various possibilities to communicate between apps:[^various]

* **Mach messages**, which are [considered harmful by Apple](https://developer.apple.com/library/mac/technotes/tn2083/_index.html#//apple_ref/doc/uid/DTS10003794-CH1-SUBSECTION31) when used on their own, mostly due to implementation problems. Use higher-level APIs instead.
* **Sockets** or, in other words, TCP network connections.
* **Distributed Notifications**, which work like regular notifications, only with higher latency. Also, notifications may be dropped by central server if the queue fills up.
* **Distributed Objects**, which don't work as advertised.
* The **Pasteboard** as a data container apps can observe and share data with.
* **XPC**, the latest and greatest, which can be used as the C XPC Services API (`libxpc`) or as Cocoa's `NSXPCConnection`.

Throughout the book, we'll use XPC to communicate between parts of the app. The XPC background service will register a Mach port for communication but we won't worry about Mach internals here.
    
[^various]: Confer the write-ups [_IPC techniques on Mac OS X_](http://www.slideshare.net/Hem_Dutt/ipc-on-mac-osx) by HEM DUTT on Slideshare, and [_Inter-Process Communication_](http://nshipster.com/inter-process-communication/) by Mattt Thompson.

## XPC

### `NSXPCConnection`

We are going to deal with `NSXPCConnection`. That's the tunnel between processes. It has to be set up in both directions for communication with a shared interface. `NSXPCConnection` will then provide proxy objects which do the XPC communicating on our behalf. This means we end up using plain old Cocoa objects on both ends and the `NSXPCConnection` takes care of the rest.

There are limitations, though. The XPC library works with the following primitive types:[^nshipsterxpc]

* Data
* Boolean
* Double
* String
* Signed Integer
* Unsigned Integer
* Date
* UUID
* Array
* Dictionary
* Null

To send custom objects across the connection, they have to conform to `NSSecureCoding`. We'll get to that later. Apple's documentation has [sufficient instructions][customobj] if you're interested. Objects are going to be copied by default. You can make them be passed by proxy instead, too, so both processes share the same instance. 
<!--ct: TODO link to when "later" is-->

I think it is really crazy that this is possible.


[^nshipsterxpc]: Mattt Thompson assembled this list [on NSHipster](http://nshipster.com/inter-process-communication/).

[customobj]: https://developer.apple.com/library/mac/documentation/MacOSX/Conceptual/BPSystemStartup/Chapters/CreatingXPCServices.html#//apple_ref/doc/uid/10000172i-SW6-SW7 "Daemons and Services Programming Guide"

### Launch Services Restrictions

You can't run XPC helper apps until the app meets certain criteria. [Apple says it pretty clear][launchserv]: 

> * Both the app and helper pass the Gatekeeper assessment. By default that means both are signed by the Mac App Store or with a Developer ID.
>     
>     > Note: This does not include your development ("Mac Developer") or distribution ("3rd Party Mac Developer Application") signing identities.
>
> * The app is installed in /Applications and the app bundle and all contents are owned by root.
> * The helper has been (manually) run at least once by the user.

If you download apps from the Mac App Store, they reside in `/Applications` and are owned by root. Passing the Gatekeeper assessment is a must in this case anyway. If you distribute outside the Mac App Store, though, you have to pay even closer attention to the other two.

Check your app's Gatekeeper assessment with the following command:

{linenos=off}
    spctl --assess -vvvv /path/to/your/application.app
    spctl --assess -vvvv /path/to/your/application.app/or/helper.app

During development, you will probably run into issues with code signing. We will look into this when we [bootstrap the project](#bootstrap).

[launchserv]: https://developer.apple.com/library/mac/documentation/Security/Conceptual/AppSandboxDesignGuide/AppSandboxInDepth/AppSandboxInDepth.html#//apple_ref/doc/uid/TP40011183-CH3-SW29 "Launching Helpers with Launch Services"
