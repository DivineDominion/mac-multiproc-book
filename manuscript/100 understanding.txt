-# Understanding the Problem: Why You Would Want to Separate Your App Into Processes

# Motivation

Let me share my background story so both you and I know what kind of problems we're going to solve.

I develop the [Word Counter for Mac](http://wordcounterapp.com). It's a system-wide progress and productivity monitor for writers. From the Decomber 2014 point of view, to make it grow and become more and more useful, the app has to deal with more incoming data. It also needs to analyze data and display meaningful information to the user. So both the background work and user interface become increasingly complex to develop.

When I added daily bar charts in 2014, I seemed to introduce a bug. I didn't know if it was my fault or something hidden within CorePlot. But it was related to interacting with the chart.

It's okay when an app crashes at first. This happens. We developers have to fix the bug and move on.

It dawned on me, though, that me taking the easy route was part of the problem. Putting the counting, analysis, and user interface into a single app means that a bug in the UI will also stop the counting. If the app crashes silently, as it did, people will lose precious data until they notice and restart the application.

* If I put the counting on a background process though, it won't stop counting when the UI crashes.
* If I put the UI for the status item and it's pop-up "Digest" view into its own Dock-less helper app, I can introduce analysis tools in a main application with a proper Dock icon.
* If I get a main app with Dock icon, the windows wouldn't need to always stay on top. In other words, this will enhance user experience because the app window behaves as expected.

The Word Counter started as a tiny app, presenting itself as a status bar item only. Then I added features which showed me that the overall design can't cope with the requirements anymore. It became too clumsy to grow further.

![201501221017 Panel Status](images/201501221017_panel-status.png)
<!--ct: TODO flow right-->

Also, introducing new features made testing harder because everything was just so involved. I put fake data at the lowest level imaginable to test-drive new UI features: I created a test target-specific directory in `~/Library/Application Support/` with dummy data just like the real app uses. What a mess!

Splitting the application into more manageable parts helps to deal with simple applications which become internally complex.

That's what this book is about: putting everything I've learned over the years together to develop a wireframe of a multi-process application.

The actual implementation of two or more processes is pretty easy. But that's only part of the solution. How do you share data? How do the parts communicate with one another? Which classes should you  share between processes?

I will cover software architecture, process implementation, and data sharing all in this book to provide an easy model to understand the problem space.


## Separating Concerns

Developing a working application is hard enough. Why on earth would you want to fragmentize it and split up the work into multiple parts?

It's very likely that you've dabbled with concurrency already. You perform tasks on a background thread (or queue) because it can make your application more responsive. Your user interface depends on the main thread. If you block it, you can't update the UI. Users won't like that. The [spinning beach ball of death][spod] is feared everywhere and can be avoided in a lot of cases. At least for me this was the premier reason to add concurrenly to my non-trivial apps.

Wheras threads still operate on a single process, to split an application into multiple processes leads to all new concerns. How do you share data? How do you send commands? We will look into these things shortly.
<!--ct: TODO have you fulfilled the promise?-->

An application composed of multiple processes has one clear advantage: every process may fail independently. That's one reason why the Chrome browser became popular: every tab has its own process, and if it crashes because of misbehaving Flash plug-ins, for example, the rest of your browser session remains safe.[^chromeproc] If your helper process crashes, you can spawn a new one from within the main application.

I argue that even non-fatal problems can be handled easier. Since your processes don't share memory, there's no obvious shortcut to get data form A to B and vice-versa. You need to define a good API to make processes cooperate.

Say you lose the internet connection during a complex background fetch. The task can't be completed, so you abort and report the problem. The process didn't crash, but it did fail. You need to notify the main application (the _client_ of the helper) about the failure. There's a well-defined point of entry for this information.

If you use background threads, you're encouraged to keep your code clean and provide sensible callbacks, too. But there's always the possibility to let the background thread reach out into other objects. For a multi-threaded application, everythings available. The context is way bigger. Multiple processes don't share anything and thus have less context. They are dumb, more like input--output black boxes.

There's clean boundaries separating the processes from one another. This encourages a different application design altogether.

Because I think it is a fairly complex application bundle I have in mind for the Word Counter, I'll stick to the separation for the sake of this book. I make it as hard as possible so both you and I learn the most from it.

The multi-part application will be composed of:

1. a background process,
2. the "big" user interface, that is, the main application with Dock icon and all, in which users can change settings and whatnot, and
3. the helper menu bar app, where a short overview is provided.


[spod]: http://en.wikipedia.org/wiki/Spinning_pinwheel

[^chromeproc]: Remember Firefox, Flash, and how your browser crashed once or twice a day because something went wrong behind the scenes? For more details, have a look at ["Why does Chrome have so many open processes?"](http://www.howtogeek.com/124218/why-does-chrome-have-so-many-open-processes/) at HowToGeek.com. I didn't know there was a Chrome comic, but it does look fun.

## Shared Data VS Inter-Process Communication

In a monolithic application, only the design of your objects introduces boundaries between components. If you add the proper accessors, everything would be available everywhere. But you limit access, introduce modules and facades, put separate concerns into separate classes. This helps keep the code readable. And it helps to change it later.

Good software architecture helps you change things later.

Coming from a monolithic app approach, one of the first questions is this: how will all three processes I have in mind share state?

They don't. Each one operates on its own. They act like individual programs, but form an application whole when you make them interact. The parts have access to the same files if you want them to. Or they can send notifications to communicate with one another. Just like every other app does.

They can share data by means of a data store, be it file-based or in a database. Although the processes are independent from one another, they can synchronize themselves by reading the same values from the same data store.

The processes can also send messages to one another. 

<!--ct: TODO from here on it gets worse-->

To share static snapshots of data may lead to data anomalies because multiple clients perform operations concurrently. Instead of looking at snapshots of data, you may want to create Then again, maybe it's not so bad after all if the database management system (DBMS) takes care of concurrency. 

We should make sure that changes take effect eventually. Programmers often want to develop programs which react immediately, even if a network connection and complex data crunching is involved. Instead, opt-in to eventual consistency and think about how much of a delay is okay for your users.

Eventual consistency basically states that all processes involved will eventually but not immediately return the most up-to-date value if no changes are performed anymore. If you change something, one process will be ahead of the others for some time. By how much they lag behind depends on your requirements.

The Word Counter for example can make use of a live counter in the menu bar. Some users will love to see the counter increase while they type. But do they have to have immediate feedback? If so, I'd need to add a way to instantly notify the status item about the change. That'd be nice, but does the experience suffer if UI updates take place every two seconds only? Maybe the counter will increase by 3 or 5, depending on the typing speed of the user. What about every half second? This will be more accurate, but it'll increase the amount of updates by a factor of 4!

To weigh the costs and payoff can relax the requirements a lot. I guess users will like to watch the counter increase immediately at first, but then they'll be busy writing and not pay attention. Thus, the update interval can start at once per second and increase to every two or three seconds when the user begins to write more. The UI can adapt to the user to save CPU cycles.

Relaxing the rules a bit in favor of subtle delays can change the entire approach you'll take. Immediacy goes hand in hand with strong coupling and synchronicity. Being okay with eventual consistency makes asynchronous notifications favorable.

So there's really two things we will have to take care of:

1. How do the processes share _state_? In the case of the Word Counter, this may be the daily total word count.
2. How do the processes _communicate_ with one another? The background task may want to inform the others about changes.

Do we need to share a data store or can we fetch all information from the background process just like you query a HTTP server for data?

<!--ct: TODO streamline this section: add introduction, clear aim-->

I encourage a server--client relationship in this case, with the background process acting as server because it's always on, and the user interfaces acting as clients.

## Inter-Process Communication on the Mac

* Mach messages
    * considered harmful by apple: https://developer.apple.com/library/mac/technotes/tn2083/_index.html#//apple_ref/doc/uid/DTS10003794-CH1-SUBSECTION31
* Sockets
* Distributed Notifications
    * Latency can be large; notifications may be dropped by central server if the queue fills up <http://www.slideshare.net/Hem_Dutt/ipc-on-mac-osx>
* Distributed Objects
* Pasteboard
* XPC
    * XPC Services API (libxpc)
    * NSXPCConnection

## XPC

### `NSXPCConnection`

We are going to deal with `NSXPCConnection`. That's the tunnel between processes. It has to be set up in both directions for communication with a shared interface. `NSXPCConnection` will then provide proxy objects which do the XPC communicating on our behalf. This means we end up using plain old Cocoa objects on both ends and the `NSXPCConnection` takes care of the rest.

There are limitations, though. The XPC library works with the following primitive types:[^nshipsterxpc]

* Data
* Boolean
* Double
* String
* Signed Integer
* Unsigned Integer
* Date
* UUID
* Array
* Dictionary
* Null

To send custom objects across the connection, they have to conform to `NSSecureCoding`. We'll get to that later. Apple's documentation has [sufficient instructions][customobj] if you're interested. Objects are going to be copied by default. You can make them be passed by proxy instead, too, so both processes share the same instance. 
<!--ct: TODO link to when "later" is-->

I think it is really crazy that this is possible.


[^nshipsterxpc]: Mattt Thompson assembled this list [on NSHipster](nshipster.com/inter-process-communication/).

[customobj]: https://developer.apple.com/library/mac/documentation/MacOSX/Conceptual/BPSystemStartup/Chapters/CreatingXPCServices.html#//apple_ref/doc/uid/10000172i-SW6-SW7 "Daemons and Services Programming Guide"

### Launch Services Restrictions

You can't run XPC helper apps until the app meets certain criteria. [Apple says it pretty clear][launchserv]: 

> * Both the app and helper pass the Gatekeeper assessment. By default that means both are signed by the Mac App Store or with a Developer ID.
>     
>     > Note: This does not include your development ("Mac Developer") or distribution ("3rd Party Mac Developer Application") signing identities.
>
> * The app is installed in /Applications and the app bundle and all contents are owned by root.
> * The helper has been (manually) run at least once by the user.

If you download apps from the Mac App Store, they reside in `/Applications` and are owned by root. Passing the Gatekeeper assessment is a must in this case anyway. If you distribute outside the Mac App Store, though, you have to pay even closer attention to the other two.

Check your app's Gatekeeper assessment with the following command:

{linenos=no}
    spctl --assess -vvvv /path/to/your/application.app
    spctl --assess -vvvv /path/to/your/application.app/or/helper.app

During development, you will probably run into issues with code signing. We will look into this when we [bootstrap the project](#bootstrap).

[launchserv]: https://developer.apple.com/library/mac/documentation/Security/Conceptual/AppSandboxDesignGuide/AppSandboxInDepth/AppSandboxInDepth.html#//apple_ref/doc/uid/TP40011183-CH3-SW29 "Launching Helpers with Launch Services"